<html>

<head>
<title>Applied Predictive Modeling - Project</title>
</head>

<body>

<p>The strategy to build these models where to identify zero variance columns and remove them from the initial Test and Training data sets.  However after initial models were built, accuracy on prediction was not desirable therefore varImp() was evaluated for gbm.  It was determined "X" was responsible for 100% of the prediction, which was obviously incorrect.  Upon further inspection X was only a consecutive index variable, therefore X was removed from the Test and Training data sets.  Final model accuracy for both gradient boosted machine and random forest models were greater than 99% accuracy.</p>

<!--begin.rcode
library(caret)
library(doMC)
end.rcode-->

<p>Register cores for multithreaded model building.</p>
<!--begin.rcode
registerDoMC(cores = 16)
end.rcode-->

<p>Set see for reproducible results.</P>
<!--begin.rcode
set.seed(555)
end.rcode-->


# Read in data
<!--begin.rcode
Test <- read.csv("pml-testing.csv")
D <- read.csv("pml-training.csv")
end.rcode-->

<p>If column in Test set is all NA, remove from Test and Training(D) data frames.</p>
<!--begin.rcode
Test.missing <- sapply(Test, function(x) all(is.na(x)) )
Test <- Test[!Test.missing]
D <- D[!Test.missing]
end.rcode-->

<p>Remove variable X from Test and Training(D) datasets </p>
<!--begin.rcode
D <- D[ , -which(names(D) %in% c("X")) ]
Test <- Test[ , -which(names(Test) %in% c("X")) ]
end.rcode-->

<p>Create stratified random sample.</p>
<!--begin.rcode
inTraining <- createDataPartition(D$classe, p = .80, list = FALSE)
D.Train <- D[ inTraining, ]
D.Test  <- D[-inTraining, ]
end.rcode-->

<p>5-fold Cross Validation repeated 3 times.</p>
<!--begin.rcode
fitControl <- trainControl(
  method = "repeatedcv",
  number = 5,
  repeats = 3)
end.rcode-->

<p>Train gradient boosted machine model using 5 fold x3 cross validation.</p>
<!--begin.rcode
gbmFit1 <- train(classe ~ ., data = as.data.frame(D.Train),
                 method = "gbm",
                 trControl = fitControl,
                 verbose = TRUE)

gbmFit1
end.rcode-->

<p>Gradient Boosted Machine Model Accuracy</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(gbmFit1)
end.rcode-->

<p>Train random forest model using 5 fold x3 cross validation.</p>
<!--begin.rcode
rfFit1 <- train(classe ~ ., data = as.data.frame(D.Train),
                method = "rf",
                trControl = fitControl,
                verbose = TRUE)

rfFit1
end.rcode-->

<p>Random Forest Model Accuracy</p>
<!--begin.rcode fig.width=7, fig.height=6
plot(rfFit1)
end.rcode-->


<p>Make predictions using each gbm and rf models.</p>
<!--begin.rcode
gbm.predict <- predict(gbmFit1, newdata = D.Test)
rf.predict <- predict(rfFit1, newdata = D.Test)
end.rcode-->

<p>Build confusion matrices from models.</p>
<!--begin.rcode
gbm.cm <- confusionMatrix(gbm.predict, D.Test$classe)
rf.cm <- confusionMatrix(rf.predict, D.Test$classe)
end.rcode-->

<p>Evaluate accuracy for each model extracted from confusion matrices.</p>
<!--begin.rcode
gbm.cm$overall['Accuracy']
rf.cm$overall['Accuracy']
end.rcode-->

</body>
</html>
